# Agentic Component Generation System

## Overview

An autonomous LangGraph-powered system that generates production-ready React components from Figma designs using GPT-4o with full LangSmith observability.

**Key Features:**
- ğŸ¤– Autonomous agent with tool calling (find similar components, write files, validate TypeScript)
- ğŸ¨ Atomic design pattern (atoms â†’ elements, molecules â†’ components, organisms â†’ modules)
- âœ… Automatic TypeScript validation after every component write
- ğŸ“Š Full LangSmith tracing of every LLM call and tool execution
- ğŸ” Semantic search of reference components for pattern reuse
- ğŸ“ˆ Token usage tracking and cost monitoring

## Architecture

```
index.js (Entry Point)
  â”‚
  â”œâ”€> Extract Figma Design (GPT-4o Vision + Structured Output)
  â”‚   â””â”€> Zod schemas for component analysis
  â”‚
  â””â”€> LangGraph Workflow
        â”‚
        â”œâ”€> Setup Node
        â”‚   â”œâ”€ Scan reference components
        â”‚   â”œâ”€ Build vector search index
        â”‚   â””â”€ Create component registry
        â”‚
        â”œâ”€> Generate Node (ChatOpenAI Agent)
        â”‚   â””â”€ Agent Loop:
        â”‚       â”œâ”€ Plan component consolidation
        â”‚       â”œâ”€ find_similar_components (semantic search)
        â”‚       â”œâ”€ write_component (create .tsx file)
        â”‚       â”œâ”€ validate_typescript (auto-validate)
        â”‚       â””â”€ Fix errors if needed â†’ repeat
        â”‚
        â””â”€> Finalize Node
            â””â”€ Report results + flush LangSmith traces
```

## File Structure

```
agentic-system/
â”œâ”€â”€ index.js                    # Main entry point
â”œâ”€â”€ config/                     # System-wide configuration
â”‚   â”œâ”€â”€ openai-client.js        # ChatOpenAI model factory
â”‚   â”œâ”€â”€ tool-executor.js        # Tool implementations + definitions
â”‚   â””â”€â”€ langsmith-config.js     # LangSmith setup & validation
â”œâ”€â”€ workflow/                   # LangGraph workflow
â”‚   â”œâ”€â”€ graph.js                # StateGraph definition
â”‚   â”œâ”€â”€ prompts/                # System prompts (extensible)
â”‚   â”‚   â””â”€â”€ agent-prompts.js    # Agent system prompts
â”‚   â””â”€â”€ nodes/                  # Workflow execution nodes
â”‚       â”œâ”€â”€ setup.js            # Resource loading node
â”‚       â”œâ”€â”€ generate.js         # ChatOpenAI agent node
â”‚       â””â”€â”€ finalize.js         # Reporting node
â””â”€â”€ tools/                      # Utility tools
    â”œâ”€â”€ figma-extractor.js      # Figma API + GPT-4o Vision
    â”œâ”€â”€ reference-scanner.js    # Component discovery
    â”œâ”€â”€ vector-search.js        # Semantic search
    â””â”€â”€ registry.js             # Component registry
```

## Environment Variables

### Required
```bash
# OpenAI
OPENAI_API_KEY=sk-...           # OpenAI API key

# Figma
FIGMA_ACCESS_TOKEN=figd_...     # Figma personal access token
```

### Optional (LangSmith Tracing)
```bash
LANGCHAIN_TRACING_V2=true                    # Enable tracing
LANGCHAIN_API_KEY=lsv2_...                   # LangSmith API key
LANGSMITH_WORKSPACE_ID=...                   # Workspace ID (for org keys)
LANGCHAIN_PROJECT=design-to-code-system      # Project name

# Model Configuration
DEFAULT_MODEL=gpt-4o                         # Or gpt-4o-mini, gpt-4, etc.
```

## Usage

### Basic Usage
```bash
node agentic-system/index.js "https://figma.com/design/FILE_KEY?node-id=X:Y"
```

### With Custom Output Directory
```bash
node agentic-system/index.js "https://figma.com/design/..." "../custom/output/path"
```

### Example
```bash
node agentic-system/index.js \
  "https://figma.com/design/qflwMPDJ4XpMn19ZGHHQCq/Atomic-Design?node-id=6-3" \
  "../atomic-design-pattern/ui"
```

## How It Works

### 1. Figma Analysis (Structured Output)
The system uses GPT-4o Vision to analyze Figma designs with Zod schemas:

```javascript
const ComponentSpecSchema = z.object({
  name: z.string(),
  atomicLevel: z.enum(['atom', 'molecule', 'organism']),
  type: z.string(),
  visualProperties: z.object({
    colors: z.string(),
    typography: z.string(),
    spacing: z.string(),
    borders: z.string(),
    shadows: z.string().nullable()
  }),
  states: z.array(z.string()),
  variants: z.array(z.string())
});
```

### 2. Agent Loop (ChatOpenAI + Tools)
The agent autonomously generates components using available tools:

**Available Tools:**
- `find_similar_components` - Semantic search for reference patterns
- `write_component` - Create React component file
- `read_file` - Read existing files
- `get_registry` - Check what components exist

**Auto-Validation:**
After every `write_component`, TypeScript validation runs automatically:
```
write_component(Button.tsx) â†’ âœ… TypeScript validation â†’ Success
write_component(Input.tsx) â†’ âŒ TypeScript errors â†’ Agent fixes â†’ Retry
```

### 3. Component Consolidation
The agent intelligently groups similar components:
- **Consolidate**: Different styles â†’ Single file with variant props
  - Example: `PrimaryButton`, `SecondaryButton` â†’ `Button.tsx` with `variant` prop
- **Separate**: Different behavior â†’ Separate files
  - Example: `TextInput` vs `SelectDropdown` â†’ Different files

### 4. Atomic Design Mapping
```
Atoms      â†’ ui/elements/     (Button.tsx, Input.tsx, Heading.tsx)
Molecules  â†’ ui/components/   (SearchBar.tsx, FormField.tsx)
Organisms  â†’ ui/modules/      (Navigation.tsx, Header.tsx, Footer.tsx)
```

## LangSmith Observability

When `LANGCHAIN_TRACING_V2=true`, every step is automatically traced:

### What You See in LangSmith Dashboard:

```
Component Generation Workflow (180s)
â”œâ”€ setup (2.1s)
â”‚  â””â”€ Loaded 45 reference components
â”‚
â”œâ”€ generate (175.3s)
â”‚  â”œâ”€ ChatOpenAI Call #1 (5.2s, $0.034)
â”‚  â”‚  â”œâ”€ Input: System prompt + 25 component specs
â”‚  â”‚  â””â”€ Output: "I'll consolidate buttons and inputs..."
â”‚  â”‚
â”‚  â”œâ”€ find_similar_components (0.3s)
â”‚  â”‚  â”œâ”€ Query: "button with variants"
â”‚  â”‚  â””â”€ Results: Button.tsx, IconButton.tsx, LinkButton.tsx
â”‚  â”‚
â”‚  â”œâ”€ ChatOpenAI Call #2 (8.1s, $0.056)
â”‚  â”‚  â””â”€ Tool call: write_component(Button.tsx)
â”‚  â”‚
â”‚  â”œâ”€ write_component (0.1s)
â”‚  â”‚  â””â”€ Created: ui/elements/Button.tsx
â”‚  â”‚
â”‚  â”œâ”€ validate_typescript (1.2s)
â”‚  â”‚  â””â”€ âœ… No errors
â”‚  â”‚
â”‚  â””â”€ ... (repeats for all components)
â”‚
â””â”€ finalize (0.2s)
   â””â”€ Generated 12 components successfully
```

**Benefits:**
- See exact prompts and responses
- Token counts and costs per call
- Tool execution traces
- Error debugging with full context
- Performance profiling

## Advanced Configuration

### Custom Model Selection
Use different models via environment variable:

```bash
# Use GPT-4o Mini (faster, cheaper)
DEFAULT_MODEL=gpt-4o-mini node agentic-system/index.js "..."

# Use GPT-4 (more capable)
DEFAULT_MODEL=gpt-4 node agentic-system/index.js "..."
```

### Synchronous Tracing (Debugging)
For guaranteed trace completion (slower):

```bash
LANGSMITH_TRACING_BACKGROUND=false node agentic-system/index.js "..."
```

## Troubleshooting

### LangSmith Trace Shows "Pending"

**Cause**: Process exited before traces uploaded.

**Solution**: Already implemented! The system uses `awaitPendingTraceBatches()` to flush traces before exit.

If you still see pending traces, check:
1. `LANGCHAIN_API_KEY` is set correctly
2. `LANGSMITH_WORKSPACE_ID` is set (required for org-scoped keys)
3. Network connectivity

### TypeScript Validation Fails

The agent automatically retries with fixes. If it gets stuck:

1. Check the error in console output
2. Look at the generated component in `ui/` folder
3. Common issues:
   - Missing imports (React, types)
   - Invalid JSX syntax
   - Type mismatches

The agent has up to 50 iterations to fix issues.

### No Components Generated

Check:
1. Figma URL is correct with `node-id` parameter
2. `FIGMA_ACCESS_TOKEN` is valid
3. `OPENAI_API_KEY` is valid
4. Run with LangSmith tracing to see where it fails

## Architecture Decisions

### Why LangGraph?
- **Structured workflow**: Clear phases (setup â†’ generate â†’ finalize)
- **State management**: Pass data between nodes cleanly
- **Extensibility**: Easy to add new nodes (e.g., visual validation, Contentful sync)
- **Observability**: Built-in LangSmith integration

### Why ChatOpenAI (not direct SDK)?
- **Automatic tracing**: Every LLM call traced in LangSmith
- **Tool calling**: Native support for function calling
- **Token tracking**: Automatic cost monitoring
- **Error handling**: Better error context

### Why Zod Schemas?
- **Structured output**: Guaranteed JSON structure from LLM
- **Type safety**: Compile-time type checking
- **Validation**: Runtime validation of LLM responses
- **Self-documenting**: Schema serves as spec

### Why Auto-Validation?
- **Quality assurance**: Every component must compile
- **Self-healing**: Agent automatically fixes errors
- **Fast feedback**: Errors caught immediately

## Performance

**Typical Run (25 components):**
- Figma analysis: 15-20 seconds
- Setup: 2-3 seconds
- Generation: 120-180 seconds (depends on complexity)
- Finalize: < 1 second

**Cost Estimate (GPT-4o):**
- Figma analysis: $0.10-0.15
- Component generation: $0.50-1.50 (depends on iterations)
- Total: ~$0.60-1.65 per run

## Future Enhancements

Planned features enabled by LangGraph architecture:

1. **Smart Component Reuse**
   - Detect existing components before generating
   - Suggest adjustments vs new generation

2. **Incremental Runs**
   - Only generate what changed since last run
   - State persistence between runs

3. **Visual Validation**
   - Playwright node to compare Figma vs Storybook
   - Automated screenshot diffing

4. **Contentful Integration**
   - Auto-generate content types from components
   - Migration scripts with codegen

5. **Parallel Generation**
   - Generate independent components concurrently
   - 3-5x faster for large designs

6. **Human-in-the-Loop**
   - Review checkpoints before file writes
   - Approve/reject/edit suggestions

## Technology Stack

- **LangGraph**: Workflow orchestration
- **LangChain**: LLM abstraction layer
- **ChatOpenAI**: GPT-4o model wrapper
- **LangSmith**: Observability platform
- **OpenAI**: LLM provider
- **Figma API**: Design extraction
- **Zod**: Schema validation
- **TypeScript**: Component validation

## License

[Your License Here]

## Contributing

[Contributing guidelines here]
